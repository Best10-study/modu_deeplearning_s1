{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab12-3 RNN with long sequences\n",
    "> RNN\n",
    "\n",
    "### 2018.09.30.(일)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro.\n",
    "\n",
    "이전까지는 data를 Manual data creation 하였었다.<br>\n",
    "근데 만약 책을 Input 하거나, 문자열이 길때는..?<br>\n",
    "이를 더 잘 생성하고자 한다.\n",
    "\n",
    "-> 자동으로 Input 하고싶다. : Better data Creation부분 !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Choi-seonyeol/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Better data Creation\n",
    "Input data를 조금 더 편하게 다룰 수는 없을까? -> Input이 아무리 길어도, 우리가 손이 많이가지 않도록 modularization 하고 싶은것."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sample = \" if you want you\"\n",
    "# 우리는 지금 각 글자들을 숫자들로 바꾸고 싶은 것!\n",
    "idx2char = list(set(sample)) \n",
    "# index -> char # Set을 통해 unique 하게 만들어준다.\n",
    "# 숫자를 문자로 지정\n",
    "char2idx =  {c: i for i, c in enumerate(idx2char)} # char -> idx \n",
    "# 문자를 숫자로 바꾸기\n",
    "sample_idx = [char2idx[c] for c in sample] # char to index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyper parameters\n",
    "\n",
    "우리가 지정해주어야 하는  hyper parameter 도 sample data에 따라 자동으로 정해주고 싶다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "dic_size = len(char2idx) # RNN input size (one hot size)\n",
    "# input의 space 를 정해주기.\n",
    "rnn_hidden_size = len(char2idx) # RNN outputsize\n",
    "# hidden layer내의 node의 개수 -> 우리는, 각 char별로 가중치를 곱해줄 것이므로, input의 space를 넣는다.\n",
    "num_classes = len(char2idx) # final output size ( RNN or softmax, etc...)\n",
    "# 결과가 output이 어떻게 나올지에 대한것 -> 여기서는  input과 같은 space에서 나오는게 당연\n",
    "batch_size = 1 # one sample data, one batch\n",
    "sequence_length = len(sample) - 1 # number of lstm unfolding ( unit # )\n",
    "# 우리 sequence의 길이 ( 전체 길이에서 1을 빼주어야 한다 : Input-output의 쌍이므로..)\n",
    "\n",
    "# 이렇게, hyper parameter도 자동화해줄 수 있다. --> sample만 바뀌면 알아서 쭉 다 바뀔 수 있도록."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = [sample_idx[:-1]] # X data sample (0 ~ n~1) hello : hell\n",
    "y_data = [sample_idx[1:]]  # Y label sample ( 1 ~ n ) hello: ello\n",
    "# input data 는 sequential 에서 앞의 글자,그때의 label은 바로 그 뒤의 글자가 된다! \n",
    "\n",
    "X = tf.placeholder(tf.int32, [None, sequence_length]) # X data\n",
    "Y = tf.placeholder(tf.int32, [None, sequence_length]) # y label\n",
    "\n",
    "X_one_hot = tf.one_hot(X, num_classes) # one hot : -> 0 1 0 0 0 0 0 0 0 \n",
    "# Tensorflow에 one_hot이라는 아름다운 함수를 만들어 놓았다...!\n",
    "# num_classes는 idx2char의 길이와 같을것 ! -> 문장내에서 발견되는 유일한 문자의 개수가 label의 개수가 될테니 ! \n",
    "# 이렇게 one_hot encoding을 할 때에는, dimmension에 차이가 있기 때문에, 항상 shape에 주의를 해야한다.(num_classis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM and Loss\n",
    "여기서부터, 실행시키는 것은 이전과 크게 다를 것이 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "cell = tf.contrib.rnn.BasicLSTMCell(num_units = rnn_hidden_size, state_is_tuple = True)\n",
    "# num_units -> hidden_size는 dictionary size 와 같다 !\n",
    "initial_state = cell.zero_state(batch_size, tf.float32)\n",
    "outputs, _states = tf.nn.dynamic_rnn(cell, X_one_hot, initial_state=initial_state, dtype=tf.float32)\n",
    "\n",
    "weights = tf.ones([batch_size, sequence_length])\n",
    "# weights를 일단 1로 초기값 만들어 주는데, 이때 shape에 주의합시다. -> batch_size : 한번 batch에서의 input data size!,sequence_length : 한번 input에서 sequence 의 쌍 \n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(logits = outputs, targets=Y, weights=weights)\n",
    "# 사실 logits으로 output를 그대로 쓰는 것은 조금 문제가 있지만, 일단 쓰자.\n",
    "loss = tf.reduce_mean(sequence_loss)\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.1).minimize(loss)\n",
    "# 일단 Adam을 쓰자 !\n",
    "\n",
    "prediction = tf.argmax(outputs, axis =2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 8 8 1 7 7 1 1]]\n",
      "[0 0 0 0 0 0 0 0 8 8 1 7 7 1 1]\n",
      "0 loss :  2.339797 Prediction :  yyyyyyyy  tuutt\n",
      "[[0 0 0 0 0 3 3 3 8 8 8 7 7 7 8]]\n",
      "[0 0 0 0 0 3 3 3 8 8 8 7 7 7 8]\n",
      "1 loss :  2.2582388 Prediction :  yyyyywww   uuu \n",
      "[[0 0 0 0 0 8 8 8 8 8 1 1 7 7 7]]\n",
      "[0 0 0 0 0 8 8 8 8 8 1 1 7 7 7]\n",
      "2 loss :  2.1811976 Prediction :  yyyyy     ttuuu\n",
      "[[0 0 0 0 0 3 3 3 9 8 1 8 0 7 7]]\n",
      "[0 0 0 0 0 3 3 3 9 8 1 8 0 7 7]\n",
      "3 loss :  2.0991642 Prediction :  yyyyywwwa t yuu\n",
      "[[0 0 0 0 0 8 8 8 8 8 1 0 0 5 5]]\n",
      "[0 0 0 0 0 8 8 8 8 8 1 0 0 5 5]\n",
      "4 loss :  2.0114987 Prediction :  yyyyy     tyyoo\n",
      "[[0 0 0 0 0 8 8 8 8 8 1 8 0 5 5]]\n",
      "[0 0 0 0 0 8 8 8 8 8 1 8 0 5 5]\n",
      "5 loss :  1.8872346 Prediction :  yyyyy     t yoo\n",
      "[[0 0 0 0 5 3 3 3 8 4 1 8 0 5 5]]\n",
      "[0 0 0 0 5 3 3 3 8 4 1 8 0 5 5]\n",
      "6 loss :  1.8046632 Prediction :  yyyyowww nt yoo\n",
      "[[0 0 0 0 5 3 3 3 8 4 1 8 0 7 7]]\n",
      "[0 0 0 0 5 3 3 3 8 4 1 8 0 7 7]\n",
      "7 loss :  1.7253637 Prediction :  yyyyowww nt yuu\n",
      "[[0 8 0 0 5 7 3 3 8 8 1 8 0 7 7]]\n",
      "[0 8 0 0 5 7 3 3 8 8 1 8 0 7 7]\n",
      "8 loss :  1.6492207 Prediction :  y yyouww  t yuu\n",
      "[[0 8 0 0 5 3 8 3 9 4 1 8 0 7 7]]\n",
      "[0 8 0 0 5 3 8 3 9 4 1 8 0 7 7]\n",
      "9 loss :  1.6126165 Prediction :  y yyow want yuu\n",
      "[[0 8 8 0 5 3 8 3 9 4 1 8 0 7 7]]\n",
      "[0 8 8 0 5 3 8 3 9 4 1 8 0 7 7]\n",
      "10 loss :  1.5653156 Prediction :  y  yow want yuu\n",
      "[[0 8 8 0 5 7 8 3 9 4 1 8 0 7 7]]\n",
      "[0 8 8 0 5 7 8 3 9 4 1 8 0 7 7]\n",
      "11 loss :  1.5326304 Prediction :  y  you want yuu\n",
      "[[0 8 8 0 5 7 3 3 9 4 1 8 0 5 7]]\n",
      "[0 8 8 0 5 7 3 3 9 4 1 8 0 5 7]\n",
      "12 loss :  1.4943683 Prediction :  y  youwwant you\n",
      "[[0 8 8 0 5 7 3 3 9 4 1 8 0 5 7]]\n",
      "[0 8 8 0 5 7 3 3 9 4 1 8 0 5 7]\n",
      "13 loss :  1.46145 Prediction :  y  youwwant you\n",
      "[[0 8 8 0 5 7 3 8 8 4 1 8 0 5 7]]\n",
      "[0 8 8 0 5 7 3 8 8 4 1 8 0 5 7]\n",
      "14 loss :  1.4230849 Prediction :  y  youw  nt you\n",
      "[[0 8 8 0 5 7 3 3 8 4 1 8 0 5 7]]\n",
      "[0 8 8 0 5 7 3 3 8 4 1 8 0 5 7]\n",
      "15 loss :  1.3888637 Prediction :  y  youww nt you\n",
      "[[0 8 8 0 5 7 3 3 9 4 1 8 0 5 7]]\n",
      "[0 8 8 0 5 7 3 3 9 4 1 8 0 5 7]\n",
      "16 loss :  1.3597294 Prediction :  y  youwwant you\n",
      "[[0 8 8 0 5 7 3 3 9 4 1 8 0 5 7]]\n",
      "[0 8 8 0 5 7 3 3 9 4 1 8 0 5 7]\n",
      "17 loss :  1.3386414 Prediction :  y  youwwant you\n",
      "[[0 8 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[0 8 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "18 loss :  1.3193368 Prediction :  y  you want you\n",
      "[[0 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[0 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "19 loss :  1.3051149 Prediction :  yf you want you\n",
      "[[0 6 8 0 5 7 3 3 9 4 1 8 0 5 7]]\n",
      "[0 6 8 0 5 7 3 3 9 4 1 8 0 5 7]\n",
      "20 loss :  1.290218 Prediction :  yf youwwant you\n",
      "[[0 6 8 0 5 7 3 3 9 4 1 8 0 5 7]]\n",
      "[0 6 8 0 5 7 3 3 9 4 1 8 0 5 7]\n",
      "21 loss :  1.2749364 Prediction :  yf youwwant you\n",
      "[[0 6 8 0 5 7 3 3 9 4 1 8 0 5 7]]\n",
      "[0 6 8 0 5 7 3 3 9 4 1 8 0 5 7]\n",
      "22 loss :  1.2618941 Prediction :  yf youwwant you\n",
      "[[0 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[0 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "23 loss :  1.2503641 Prediction :  yf you want you\n",
      "[[0 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[0 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "24 loss :  1.2387052 Prediction :  yf you want you\n",
      "[[0 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[0 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "25 loss :  1.2274702 Prediction :  yf you want you\n",
      "[[0 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[0 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "26 loss :  1.2193868 Prediction :  yf you want you\n",
      "[[0 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[0 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "27 loss :  1.2147442 Prediction :  yf you want you\n",
      "[[0 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[0 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "28 loss :  1.2101238 Prediction :  yf you want you\n",
      "[[0 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[0 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "29 loss :  1.2032199 Prediction :  yf you want you\n",
      "[[0 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[0 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "30 loss :  1.1959456 Prediction :  yf you want you\n",
      "[[0 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[0 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "31 loss :  1.1902068 Prediction :  yf you want you\n",
      "[[0 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[0 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "32 loss :  1.1854893 Prediction :  yf you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "33 loss :  1.1797247 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "34 loss :  1.1722913 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "35 loss :  1.164942 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "36 loss :  1.1579363 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "37 loss :  1.1495389 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "38 loss :  1.1409804 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "39 loss :  1.133248 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "40 loss :  1.1265852 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "41 loss :  1.1205866 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "42 loss :  1.1149406 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "43 loss :  1.109976 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "44 loss :  1.1054684 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "45 loss :  1.100976 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "46 loss :  1.0967057 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "47 loss :  1.0928452 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "48 loss :  1.0893024 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "49 loss :  1.0860149 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "50 loss :  1.0831587 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "51 loss :  1.0806389 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "52 loss :  1.078304 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "53 loss :  1.0761414 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "54 loss :  1.0742022 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "55 loss :  1.072387 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "56 loss :  1.070619 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "57 loss :  1.0689429 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "58 loss :  1.0673277 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "59 loss :  1.0656275 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "60 loss :  1.0638007 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "61 loss :  1.0619038 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "62 loss :  1.0599784 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "63 loss :  1.0580804 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "64 loss :  1.0563072 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "65 loss :  1.0546707 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "66 loss :  1.0531987 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "67 loss :  1.051964 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "68 loss :  1.0508335 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "69 loss :  1.0497618 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "70 loss :  1.0489014 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "71 loss :  1.0481138 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "72 loss :  1.0473396 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "73 loss :  1.0466641 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "74 loss :  1.0459327 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "75 loss :  1.0452392 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "76 loss :  1.0445465 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "77 loss :  1.0437956 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "78 loss :  1.0431079 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "79 loss :  1.0423839 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "80 loss :  1.0416667 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "81 loss :  1.0409887 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "82 loss :  1.0402956 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "83 loss :  1.0396428 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "84 loss :  1.0389807 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "85 loss :  1.0383337 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "86 loss :  1.0376985 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "87 loss :  1.037025 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "88 loss :  1.0363421 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "89 loss :  1.0355918 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "90 loss :  1.0347611 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "91 loss :  1.0337942 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "92 loss :  1.032633 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "93 loss :  1.0312953 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "94 loss :  1.029853 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "95 loss :  1.0284674 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "96 loss :  1.0272777 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "97 loss :  1.0263176 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "98 loss :  1.025534 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "99 loss :  1.0248522 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "100 loss :  1.0242127 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "101 loss :  1.0235773 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "102 loss :  1.0229253 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "103 loss :  1.0222558 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "104 loss :  1.0215948 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "105 loss :  1.0209745 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "106 loss :  1.0204042 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "107 loss :  1.0198636 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "108 loss :  1.0193287 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "109 loss :  1.018788 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "110 loss :  1.0182394 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "111 loss :  1.0176857 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "112 loss :  1.0171292 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "113 loss :  1.0165734 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "114 loss :  1.0160246 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "115 loss :  1.015494 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "116 loss :  1.0149969 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "117 loss :  1.0145466 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "118 loss :  1.014148 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "119 loss :  1.0137968 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "120 loss :  1.0134833 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "121 loss :  1.0131984 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "122 loss :  1.0129344 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "123 loss :  1.0126871 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "124 loss :  1.0124534 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "125 loss :  1.0122306 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "126 loss :  1.012017 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "127 loss :  1.0118114 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "128 loss :  1.0116119 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "129 loss :  1.0114172 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "130 loss :  1.0112246 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "131 loss :  1.011032 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "132 loss :  1.0108367 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "133 loss :  1.010636 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "134 loss :  1.0104265 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "135 loss :  1.0102057 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "136 loss :  1.0099708 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "137 loss :  1.0097202 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "138 loss :  1.0094534 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "139 loss :  1.0091714 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "140 loss :  1.0088773 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "141 loss :  1.0085771 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "142 loss :  1.0082802 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "143 loss :  1.0079975 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "144 loss :  1.0077426 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "145 loss :  1.0075245 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "146 loss :  1.0073457 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "147 loss :  1.0072002 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "148 loss :  1.0070792 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "149 loss :  1.0069726 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "150 loss :  1.0068727 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "151 loss :  1.0067741 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "152 loss :  1.0066743 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "153 loss :  1.0065722 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "154 loss :  1.0064685 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "155 loss :  1.006364 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "156 loss :  1.0062603 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "157 loss :  1.0061581 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "158 loss :  1.0060585 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "159 loss :  1.0059617 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "160 loss :  1.005868 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "161 loss :  1.0057771 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "162 loss :  1.0056888 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "163 loss :  1.0056022 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "164 loss :  1.0055165 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "165 loss :  1.0054307 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "166 loss :  1.0053432 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "167 loss :  1.0052525 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "168 loss :  1.0051565 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "169 loss :  1.0050532 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "170 loss :  1.0049396 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "171 loss :  1.0048128 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "172 loss :  1.0046705 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "173 loss :  1.0045117 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "174 loss :  1.0043391 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "175 loss :  1.0041617 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "176 loss :  1.0039955 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "177 loss :  1.0038582 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "178 loss :  1.0037599 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "179 loss :  1.0036947 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "180 loss :  1.0036429 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "181 loss :  1.0035837 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "182 loss :  1.0035051 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "183 loss :  1.0034081 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "184 loss :  1.003302 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "185 loss :  1.0031967 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "186 loss :  1.0030997 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "187 loss :  1.0030136 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "188 loss :  1.002939 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "189 loss :  1.0028746 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "190 loss :  1.0028179 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "191 loss :  1.002767 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "192 loss :  1.00272 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "193 loss :  1.0026757 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "194 loss :  1.002633 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "195 loss :  1.0025915 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "196 loss :  1.002551 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "197 loss :  1.0025113 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "198 loss :  1.0024724 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "199 loss :  1.0024346 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "200 loss :  1.0023979 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "201 loss :  1.0023623 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "202 loss :  1.0023279 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "203 loss :  1.0022949 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "204 loss :  1.0022628 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "205 loss :  1.0022321 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "206 loss :  1.0022024 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "207 loss :  1.0021737 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "208 loss :  1.0021456 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "209 loss :  1.0021187 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "210 loss :  1.0020926 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "211 loss :  1.0020669 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "212 loss :  1.0020419 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "213 loss :  1.0020176 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "214 loss :  1.0019938 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "215 loss :  1.0019705 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "216 loss :  1.0019476 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "217 loss :  1.0019251 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "218 loss :  1.001903 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "219 loss :  1.0018815 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "220 loss :  1.0018601 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "221 loss :  1.0018393 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "222 loss :  1.0018187 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "223 loss :  1.0017984 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "224 loss :  1.0017786 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "225 loss :  1.0017589 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "226 loss :  1.0017395 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "227 loss :  1.0017204 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "228 loss :  1.0017018 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "229 loss :  1.0016832 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "230 loss :  1.001665 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "231 loss :  1.0016471 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "232 loss :  1.0016295 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "233 loss :  1.001612 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "234 loss :  1.0015948 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "235 loss :  1.0015777 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "236 loss :  1.0015609 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "237 loss :  1.0015444 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "238 loss :  1.0015281 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "239 loss :  1.001512 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "240 loss :  1.0014961 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "241 loss :  1.0014803 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "242 loss :  1.0014648 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "243 loss :  1.0014495 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "244 loss :  1.0014343 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "245 loss :  1.0014193 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "246 loss :  1.0014045 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "247 loss :  1.0013899 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "248 loss :  1.0013756 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "249 loss :  1.0013611 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "250 loss :  1.0013471 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "251 loss :  1.0013331 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "252 loss :  1.0013193 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "253 loss :  1.0013056 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "254 loss :  1.001292 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "255 loss :  1.0012786 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "256 loss :  1.0012654 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "257 loss :  1.0012523 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "258 loss :  1.0012394 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "259 loss :  1.0012267 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "260 loss :  1.0012139 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "261 loss :  1.0012014 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "262 loss :  1.001189 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "263 loss :  1.0011766 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "264 loss :  1.0011646 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "265 loss :  1.0011525 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "266 loss :  1.0011405 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "267 loss :  1.0011287 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "268 loss :  1.001117 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "269 loss :  1.0011053 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "270 loss :  1.0010939 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "271 loss :  1.0010825 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "272 loss :  1.0010713 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "273 loss :  1.0010602 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "274 loss :  1.0010493 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "275 loss :  1.0010383 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "276 loss :  1.0010273 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "277 loss :  1.0010166 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "278 loss :  1.001006 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "279 loss :  1.0009955 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "280 loss :  1.0009851 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "281 loss :  1.0009748 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "282 loss :  1.0009645 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "283 loss :  1.0009544 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "284 loss :  1.0009444 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "285 loss :  1.0009342 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "286 loss :  1.0009245 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "287 loss :  1.0009147 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "288 loss :  1.0009049 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "289 loss :  1.0008954 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "290 loss :  1.0008858 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "291 loss :  1.0008763 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "292 loss :  1.000867 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "293 loss :  1.0008577 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "294 loss :  1.0008485 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "295 loss :  1.0008396 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "296 loss :  1.0008304 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "297 loss :  1.0008215 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "298 loss :  1.0008125 Prediction :  if you want you\n",
      "[[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]]\n",
      "[2 6 8 0 5 7 8 3 9 4 1 8 0 5 7]\n",
      "299 loss :  1.0008038 Prediction :  if you want you\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(300):\n",
    "        l, _ = sess.run([loss, train],feed_dict={X: x_data, Y:y_data})\n",
    "        result = sess.run(prediction, feed_dict = {X: x_data})\n",
    "        # print char using dic\n",
    "        result_str = [idx2char[c] for c in np.squeeze(result)]\n",
    "        print(i, \"loss : \", l, \"Prediction : \", \"\".join(result_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Really long sentence?\n",
    "\n",
    "이제 정말 긴 문장을 한번 학습시켜 보겠다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sentence = (\"if you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이 문장에 대해서, training data set은\n",
    "![lec12_14](../../img/lec12_14.png)\n",
    "와 같이, 10개(batch_size)씩 input과 각각 다음 글자를 output으로 갖는 169개의 data가 될것.<br>\n",
    "168개나 되므로, 우리는 minibatch로 구현할 예정입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making dataset\n",
    "위와 같은 dataset을 자동으로 만들어 주는 코드를 작성하여 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 if you wan -> f you want\n",
      "1 f you want ->  you want \n",
      "2  you want  -> you want t\n",
      "3 you want t -> ou want to\n",
      "4 ou want to -> u want to \n",
      "5 u want to  ->  want to b\n",
      "6  want to b -> want to bu\n",
      "7 want to bu -> ant to bui\n",
      "8 ant to bui -> nt to buil\n",
      "9 nt to buil -> t to build\n",
      "10 t to build ->  to build \n",
      "11  to build  -> to build a\n",
      "12 to build a -> o build a \n",
      "13 o build a  ->  build a s\n",
      "14  build a s -> build a sh\n",
      "15 build a sh -> uild a shi\n",
      "16 uild a shi -> ild a ship\n",
      "17 ild a ship -> ld a ship,\n",
      "18 ld a ship, -> d a ship, \n",
      "19 d a ship,  ->  a ship, d\n",
      "20  a ship, d -> a ship, do\n",
      "21 a ship, do ->  ship, don\n",
      "22  ship, don -> ship, don'\n",
      "23 ship, don' -> hip, don't\n",
      "24 hip, don't -> ip, don't \n",
      "25 ip, don't  -> p, don't d\n",
      "26 p, don't d -> , don't dr\n",
      "27 , don't dr ->  don't dru\n",
      "28  don't dru -> don't drum\n",
      "29 don't drum -> on't drum \n",
      "30 on't drum  -> n't drum u\n",
      "31 n't drum u -> 't drum up\n",
      "32 't drum up -> t drum up \n",
      "33 t drum up  ->  drum up p\n",
      "34  drum up p -> drum up pe\n",
      "35 drum up pe -> rum up peo\n",
      "36 rum up peo -> um up peop\n",
      "37 um up peop -> m up peopl\n",
      "38 m up peopl ->  up people\n",
      "39  up people -> up people \n",
      "40 up people  -> p people t\n",
      "41 p people t ->  people to\n",
      "42  people to -> people tog\n",
      "43 people tog -> eople toge\n",
      "44 eople toge -> ople toget\n",
      "45 ople toget -> ple togeth\n",
      "46 ple togeth -> le togethe\n",
      "47 le togethe -> e together\n",
      "48 e together ->  together \n",
      "49  together  -> together t\n",
      "50 together t -> ogether to\n",
      "51 ogether to -> gether to \n",
      "52 gether to  -> ether to c\n",
      "53 ether to c -> ther to co\n",
      "54 ther to co -> her to col\n",
      "55 her to col -> er to coll\n",
      "56 er to coll -> r to colle\n",
      "57 r to colle ->  to collec\n",
      "58  to collec -> to collect\n",
      "59 to collect -> o collect \n",
      "60 o collect  ->  collect w\n",
      "61  collect w -> collect wo\n",
      "62 collect wo -> ollect woo\n",
      "63 ollect woo -> llect wood\n",
      "64 llect wood -> lect wood \n",
      "65 lect wood  -> ect wood a\n",
      "66 ect wood a -> ct wood an\n",
      "67 ct wood an -> t wood and\n",
      "68 t wood and ->  wood and \n",
      "69  wood and  -> wood and d\n",
      "70 wood and d -> ood and do\n",
      "71 ood and do -> od and don\n",
      "72 od and don -> d and don'\n",
      "73 d and don' ->  and don't\n",
      "74  and don't -> and don't \n",
      "75 and don't  -> nd don't a\n",
      "76 nd don't a -> d don't as\n",
      "77 d don't as ->  don't ass\n",
      "78  don't ass -> don't assi\n",
      "79 don't assi -> on't assig\n",
      "80 on't assig -> n't assign\n",
      "81 n't assign -> 't assign \n",
      "82 't assign  -> t assign t\n",
      "83 t assign t ->  assign th\n",
      "84  assign th -> assign the\n",
      "85 assign the -> ssign them\n",
      "86 ssign them -> sign them \n",
      "87 sign them  -> ign them t\n",
      "88 ign them t -> gn them ta\n",
      "89 gn them ta -> n them tas\n",
      "90 n them tas ->  them task\n",
      "91  them task -> them tasks\n",
      "92 them tasks -> hem tasks \n",
      "93 hem tasks  -> em tasks a\n",
      "94 em tasks a -> m tasks an\n",
      "95 m tasks an ->  tasks and\n",
      "96  tasks and -> tasks and \n",
      "97 tasks and  -> asks and w\n",
      "98 asks and w -> sks and wo\n",
      "99 sks and wo -> ks and wor\n",
      "100 ks and wor -> s and work\n",
      "101 s and work ->  and work,\n",
      "102  and work, -> and work, \n",
      "103 and work,  -> nd work, b\n",
      "104 nd work, b -> d work, bu\n",
      "105 d work, bu ->  work, but\n",
      "106  work, but -> work, but \n",
      "107 work, but  -> ork, but r\n",
      "108 ork, but r -> rk, but ra\n",
      "109 rk, but ra -> k, but rat\n",
      "110 k, but rat -> , but rath\n",
      "111 , but rath ->  but rathe\n",
      "112  but rathe -> but rather\n",
      "113 but rather -> ut rather \n",
      "114 ut rather  -> t rather t\n",
      "115 t rather t ->  rather te\n",
      "116  rather te -> rather tea\n",
      "117 rather tea -> ather teac\n",
      "118 ather teac -> ther teach\n",
      "119 ther teach -> her teach \n",
      "120 her teach  -> er teach t\n",
      "121 er teach t -> r teach th\n",
      "122 r teach th ->  teach the\n",
      "123  teach the -> teach them\n",
      "124 teach them -> each them \n",
      "125 each them  -> ach them t\n",
      "126 ach them t -> ch them to\n",
      "127 ch them to -> h them to \n",
      "128 h them to  ->  them to l\n",
      "129  them to l -> them to lo\n",
      "130 them to lo -> hem to lon\n",
      "131 hem to lon -> em to long\n",
      "132 em to long -> m to long \n",
      "133 m to long  ->  to long f\n",
      "134  to long f -> to long fo\n",
      "135 to long fo -> o long for\n",
      "136 o long for ->  long for \n",
      "137  long for  -> long for t\n",
      "138 long for t -> ong for th\n",
      "139 ong for th -> ng for the\n",
      "140 ng for the -> g for the \n",
      "141 g for the  ->  for the e\n",
      "142  for the e -> for the en\n",
      "143 for the en -> or the end\n",
      "144 or the end -> r the endl\n",
      "145 r the endl ->  the endle\n",
      "146  the endle -> the endles\n",
      "147 the endles -> he endless\n",
      "148 he endless -> e endless \n",
      "149 e endless  ->  endless i\n",
      "150  endless i -> endless im\n",
      "151 endless im -> ndless imm\n",
      "152 ndless imm -> dless imme\n",
      "153 dless imme -> less immen\n",
      "154 less immen -> ess immens\n",
      "155 ess immens -> ss immensi\n",
      "156 ss immensi -> s immensit\n",
      "157 s immensit ->  immensity\n",
      "158  immensity -> immensity \n",
      "159 immensity  -> mmensity o\n",
      "160 mmensity o -> mensity of\n",
      "161 mensity of -> ensity of \n",
      "162 ensity of  -> nsity of t\n",
      "163 nsity of t -> sity of th\n",
      "164 sity of th -> ity of the\n",
      "165 ity of the -> ty of the \n",
      "166 ty of the  -> y of the s\n",
      "167 y of the s ->  of the se\n",
      "168  of the se -> of the sea\n",
      "169 of the sea -> f the sea.\n"
     ]
    }
   ],
   "source": [
    "char_set = list(set(sentence))\n",
    "# Sentence 내의 Unique 한 character를 뽑아낸다.\n",
    "char_dic = {w: i for i, w in enumerate(char_set)} # char -> idx \n",
    "# 각 character를 indexing 하기!\n",
    "seq_length = 10\n",
    "# 한번의 sequence 크기를 몇으로 할 지 지정\n",
    "\n",
    "dataX = []\n",
    "dataY = []\n",
    "# 0번째부터, 마지막 10개의 숫자까지 돌린다 !\n",
    "for i in range(0, len(sentence) - seq_length):\n",
    "    x_str = sentence[i: i + seq_length]\n",
    "    y_str = sentence[i + 1: i + seq_length + 1]\n",
    "    print(i, x_str, \"->\", y_str)\n",
    "    \n",
    "    x = [char_dic[c] for c in x_str] # x str to index  : 즉, x_str내의 값을 index로 바꾸어 저장\n",
    "    y = [char_dic[c] for c in y_str] # y str to index\n",
    "    \n",
    "    dataX.append(x)\n",
    "    dataY.append(y)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN parameters\n",
    "이런 hyper parameter 까지 다 자동으로 만들어 줄 수 있다.<br>\n",
    "내가 원한다면 seq_length를 내 마음대로 넣어주어도 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dim = len(char_set)\n",
    "hidden_size = len(char_set)\n",
    "num_classes = len(char_set)\n",
    "seq_length = 10 # Any orbitary number\n",
    "batch_size = len(dataX)\n",
    "# 이전까지는 데이터의 개수가 끽해야 몇개 안되서 그냥 했는데, 이번에는 169개나 되는 데이터이기 때문에,\n",
    "# minibatch로 처리하기 위해 batch_size를 지정!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM and Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.int32, [None, seq_length]) # X data\n",
    "Y = tf.placeholder(tf.int32, [None, seq_length]) # Y Label\n",
    "\n",
    "X_one_hot = tf.one_hot(X, num_classes) # one_hot : 1 -> 0 1 0 0 0 0 0 0 0 0\n",
    "\n",
    "# Make a lstm cell with hidden_size (each unit output vector size)\n",
    "def lstm_cell():\n",
    "    cell = tf.contrib.rnn.BasicLSTMCell(hidden_size, state_is_tuple=True)\n",
    "    return cell\n",
    "\n",
    "multi_cells = tf.contrib.rnn.MultiRNNCell([lstm_cell() for _ in range(2)], state_is_tuple=True)\n",
    "outputs, _states = tf.nn.dynamic_rnn( multi_cells, X_one_hot, dtype = tf.float32)\n",
    "\n",
    "# FC layer\n",
    "X_for_fc = tf.reshape(outputs, [-1, hidden_size])\n",
    "outputs = tf.contrib.layers.fully_connected(X_for_fc, num_classes, activation_fn=None)\n",
    "\n",
    "# reshape out for sequence_loss\n",
    "outputs = tf.reshape(outputs, [batch_size, seq_length, num_classes])\n",
    "\n",
    "weights = tf.ones([batch_size, seq_length])\n",
    "\n",
    "sequence_loss = tf.contrib.seq2seq.sequence_loss(logits = outputs, targets = Y, weights=weights)\n",
    "loss = tf.reduce_mean(sequence_loss)\n",
    "train = tf.train.AdamOptimizer(learning_rate=0.1).minimize(loss)\n",
    "\n",
    "prediction = tf.argmax(outputs, axis=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499 0 l you want 0.22883578\n",
      "499 1  you want  0.22883578\n",
      "499 2 tou want t 0.22883578\n",
      "499 3  u want to 0.22883578\n",
      "499 4 n want to  0.22883578\n",
      "499 5  want to b 0.22883578\n",
      "499 6 tont to bu 0.22883578\n",
      "499 7 ont to bui 0.22883578\n",
      "499 8 nd to buil 0.22883578\n",
      "499 9 d to build 0.22883578\n",
      "499 10 hdo build  0.22883578\n",
      "499 11 to build a 0.22883578\n",
      "499 12 h luild a  0.22883578\n",
      "499 13 nluild a s 0.22883578\n",
      "499 14 tuild a sh 0.22883578\n",
      "499 15 uild a shi 0.22883578\n",
      "499 16  ld a ship 0.22883578\n",
      "499 17 ld a ship, 0.22883578\n",
      "499 18 e a ship,  0.22883578\n",
      "499 19  anship, d 0.22883578\n",
      "499 20 tnship, do 0.22883578\n",
      "499 21 nship, don 0.22883578\n",
      "499 22 thip, don' 0.22883578\n",
      "499 23  ip, don't 0.22883578\n",
      "499 24 ep, don't  0.22883578\n",
      "499 25 l, don't d 0.22883578\n",
      "499 26 , don't dr 0.22883578\n",
      "499 27  bon't dru 0.22883578\n",
      "499 28 ton't drum 0.22883578\n",
      "499 29  n't drum  0.22883578\n",
      "499 30 n't drum u 0.22883578\n",
      "499 31 dt drum up 0.22883578\n",
      "499 32 t drum up  0.22883578\n",
      "499 33 hdrum up p 0.22883578\n",
      "499 34 toum up pe 0.22883578\n",
      "499 35  um up peo 0.22883578\n",
      "499 36  m up peop 0.22883578\n",
      "499 37   up peopl 0.22883578\n",
      "499 38  tp people 0.22883578\n",
      "499 39 tp people  0.22883578\n",
      "499 40   people t 0.22883578\n",
      "499 41 ,people to 0.22883578\n",
      "499 42 teople tog 0.22883578\n",
      "499 43 ,ople toge 0.22883578\n",
      "499 44 mple toget 0.22883578\n",
      "499 45 nle togeth 0.22883578\n",
      "499 46 ,e togethe 0.22883578\n",
      "499 47 e together 0.22883578\n",
      "499 48 meogether  0.22883578\n",
      "499 49 to ether t 0.22883578\n",
      "499 50 h ether to 0.22883578\n",
      "499 51 nether to  0.22883578\n",
      "499 52  ther to c 0.22883578\n",
      "499 53 mher to co 0.22883578\n",
      "499 54 hem to col 0.22883578\n",
      "499 55 em te coll 0.22883578\n",
      "499 56 m te colle 0.22883578\n",
      "499 57  th collec 0.22883578\n",
      "499 58 to bollect 0.22883578\n",
      "499 59 h lollect  0.22883578\n",
      "499 60 nlollect w 0.22883578\n",
      "499 61 tollect wo 0.22883578\n",
      "499 62 ollect woo 0.22883578\n",
      "499 63 nlect wood 0.22883578\n",
      "499 64 eect wood  0.22883578\n",
      "499 65 e t wood a 0.22883578\n",
      "499 66 mt wood an 0.22883578\n",
      "499 67 o wood and 0.22883578\n",
      "499 68 hdood and  0.22883578\n",
      "499 69 tood and d 0.22883578\n",
      "499 70 ood and do 0.22883578\n",
      "499 71 nd and don 0.22883578\n",
      "499 72 n and don' 0.22883578\n",
      "499 73  and don't 0.22883578\n",
      "499 74 tnd won't  0.22883578\n",
      "499 75 nd won't a 0.22883578\n",
      "499 76 d won't as 0.22883578\n",
      "499 77  aon't ass 0.22883578\n",
      "499 78 ton't dssi 0.22883578\n",
      "499 79  n't dssig 0.22883578\n",
      "499 80 n't dssign 0.22883578\n",
      "499 81 dt dssign  0.22883578\n",
      "499 82 t dssign t 0.22883578\n",
      "499 83 hdssign th 0.22883578\n",
      "499 84 tnsign the 0.22883578\n",
      "499 85 nsign them 0.22883578\n",
      "499 86  ign them  0.22883578\n",
      "499 87  tn them t 0.22883578\n",
      "499 88 ln them ta 0.22883578\n",
      "499 89   them tas 0.22883578\n",
      "499 90 dthem task 0.22883578\n",
      "499 91 toem tasks 0.22883578\n",
      "499 92 hem tosks  0.22883578\n",
      "499 93 em tasks a 0.22883578\n",
      "499 94 m tasks an 0.22883578\n",
      "499 95  tasks and 0.22883578\n",
      "499 96 tosks and  0.22883578\n",
      "499 97 hsks and w 0.22883578\n",
      "499 98 nss and wo 0.22883578\n",
      "499 99  s and wor 0.22883578\n",
      "499 100 , and work 0.22883578\n",
      "499 101  ind work, 0.22883578\n",
      "499 102 tnd work,  0.22883578\n",
      "499 103 nd work, b 0.22883578\n",
      "499 104 d work, bu 0.22883578\n",
      "499 105  aork, but 0.22883578\n",
      "499 106 took, but  0.22883578\n",
      "499 107 ook, but r 0.22883578\n",
      "499 108 n , but ra 0.22883578\n",
      "499 109  , but rat 0.22883578\n",
      "499 110 , but rath 0.22883578\n",
      "499 111  but rathe 0.22883578\n",
      "499 112 tui rather 0.22883578\n",
      "499 113 ui rather  0.22883578\n",
      "499 114   rather t 0.22883578\n",
      "499 115 hdather te 0.22883578\n",
      "499 116 tather tea 0.22883578\n",
      "499 117  ther teac 0.22883578\n",
      "499 118 nher teach 0.22883578\n",
      "499 119 hem toach  0.22883578\n",
      "499 120 em teach t 0.22883578\n",
      "499 121 m teach th 0.22883578\n",
      "499 122  thach the 0.22883578\n",
      "499 123 toach them 0.22883578\n",
      "499 124 hach them  0.22883578\n",
      "499 125 mch them t 0.22883578\n",
      "499 126 nh them to 0.22883578\n",
      "499 127 o them to  0.22883578\n",
      "499 128 ethem to l 0.22883578\n",
      "499 129 toem ta lo 0.22883578\n",
      "499 130 hem to lon 0.22883578\n",
      "499 131 em ta long 0.22883578\n",
      "499 132 m ta long  0.22883578\n",
      "499 133  ta long f 0.22883578\n",
      "499 134 to bong fo 0.22883578\n",
      "499 135 h long for 0.22883578\n",
      "499 136 nlong for  0.22883578\n",
      "499 137 tong for t 0.22883578\n",
      "499 138 eng for th 0.22883578\n",
      "499 139 n' for the 0.22883578\n",
      "499 140 d for the  0.22883578\n",
      "499 141  for the e 0.22883578\n",
      "499 142 tor the en 0.22883578\n",
      "499 143  r the end 0.22883578\n",
      "499 144 n the endl 0.22883578\n",
      "499 145  the endle 0.22883578\n",
      "499 146 toemendles 0.22883578\n",
      "499 147 hemendless 0.22883578\n",
      "499 148 emendless  0.22883578\n",
      "499 149 mendless i 0.22883578\n",
      "499 150 tndless im 0.22883578\n",
      "499 151 msless imm 0.22883578\n",
      "499 152 d ess imme 0.22883578\n",
      "499 153  ess immen 0.22883578\n",
      "499 154 e s immens 0.22883578\n",
      "499 155 ms immensi 0.22883578\n",
      "499 156  iimmensit 0.22883578\n",
      "499 157  immensity 0.22883578\n",
      "499 158 tmmensity  0.22883578\n",
      "499 159 lmensity o 0.22883578\n",
      "499 160  ensity of 0.22883578\n",
      "499 161  nsity of  0.22883578\n",
      "499 162 msity of t 0.22883578\n",
      "499 163 dity of th 0.22883578\n",
      "499 164  ty of the 0.22883578\n",
      "499 165 ly of the  0.22883578\n",
      "499 166 h of the s 0.22883578\n",
      "499 167  of the se 0.22883578\n",
      "499 168 tf the sea 0.22883578\n",
      "499 169 n the sea. 0.22883578\n",
      "g you want to build a ship, don't drum up people together to collect wood and don't assign them tasks and work, but rather teach them to long for the endless immensity of the sea."
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(500):\n",
    "        _, l, results = sess.run(\n",
    "            [train, loss, outputs], feed_dict={X: dataX, Y: dataY})\n",
    "    for j, result in enumerate(results):\n",
    "        index = np.argmax(result, axis=1)\n",
    "        print(i, j, ''.join([char_set[t] for t in index]), l)\n",
    "    # Let's print the last char of each result to check it works\n",
    "    results = sess.run(outputs, feed_dict={X: dataX})\n",
    "    for j, result in enumerate(results):\n",
    "        index = np.argmax(result, axis=1)\n",
    "        if j is 0:  # print all for the first result to make a sentence\n",
    "            print(''.join([char_set[t] for t in index]), end='')\n",
    "        else:\n",
    "            print(char_set[index[-1]], end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
