{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 07. lab07-2_Meet MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[MNIST DATA SET](http://yann.lecun.com/exdb/mnist/)\n",
    "\n",
    "MNIST DATA :\n",
    "![lec07_6](../../img/lec07_6.png)\n",
    "X -> Input data : 28 * 27 * 1 데이터로, 총 784개의 x features\n",
    "Y -> Output data : 0 ~ 9 사이의 10가지 class 의 output  값 (  one-hot incoding 으로 출력)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#MNIST data\n",
    "mnist_trainset = datasets.MNIST(root = './data',train =True,transform=transforms.ToTensor(),download=True)\n",
    "mnist_testset = datasets.MNIST(root = './data', train = False, transform=transforms.ToTensor(),download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# Data Loader (Input Pipeline)\n",
    "train_loader = DataLoader(dataset=mnist_trainset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = DataLoader(dataset=mnist_testset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.linear = nn.Linear(784, 10,bias = True) # 2 in and 1 out\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 784)\n",
    "        y_pred = self.linear(x)\n",
    "        F.softmax(y_pred,dim = 1)\n",
    "        return y_pred\n",
    "    \n",
    "model = Model()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0\tLoss: 2.324386\n",
      "Train Epoch: 1\tLoss: 1.978600\n",
      "Train Epoch: 2\tLoss: 1.695961\n",
      "Train Epoch: 3\tLoss: 1.461045\n",
      "Train Epoch: 4\tLoss: 1.256177\n",
      "Train Epoch: 5\tLoss: 1.106402\n",
      "Train Epoch: 6\tLoss: 1.008929\n",
      "Train Epoch: 7\tLoss: 0.932672\n",
      "Train Epoch: 8\tLoss: 0.867257\n",
      "Train Epoch: 9\tLoss: 0.807285\n",
      "Train Epoch: 10\tLoss: 0.752935\n",
      "Train Epoch: 11\tLoss: 0.716198\n",
      "Train Epoch: 12\tLoss: 0.684900\n",
      "Train Epoch: 13\tLoss: 0.661016\n",
      "Train Epoch: 14\tLoss: 0.635878\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "\n",
    "    avg_cost = 0\n",
    "    total_batch = int(len(mnist_trainset) / batch_size)\n",
    "    model.train()\n",
    "    \n",
    "    for idx, (batch_xs, batch_ys) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(batch_xs)\n",
    "        loss = criterion(y_pred, batch_ys)\n",
    "        loss.backward()\n",
    "        avg_cost += loss / total_batch\n",
    "    print('Train Epoch: {}\\tLoss: {:.6f}'.format(epoch, avg_cost))\n",
    "    optimizer.step()\n",
    "\n",
    "#         if idx % 10 == 0:\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                 epoch, idx * len(data), len(train_loader.dataset),\n",
    "#                 100. * idx / len(train_loader), loss.data[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "for data, target in test_loader:\n",
    "    data, target = Variable(data), Variable(target)\n",
    "    output = model(data)\n",
    "    # sum up batch loss\n",
    "    test_loss += criterion(output, target).item()\n",
    "    # get the index of the max log-probability\n",
    "    pred = output.data.max(1, keepdim=True)[1]\n",
    "    correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Average loss: 0.0058, Accuracy: 8291/10000 (82%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss /= len(test_loader.dataset)\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
