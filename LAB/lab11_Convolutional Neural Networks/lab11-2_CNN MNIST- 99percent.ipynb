{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. Lab11-2 CNN MNIST: 99%\n",
    "\n",
    "> Convolutional Neural Networks\n",
    "\n",
    "### 2018.09.29 (토)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lab11-1 에서 진행한 CNN에서 CONV 와 POOL layer 를 하나씩 더 준다면.\n",
    "![lec11_25](../../img/lec11_25.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Choi-seonyeol/anaconda3/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-8bf8ae5a5303>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From /Users/Choi-seonyeol/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From /Users/Choi-seonyeol/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/Choi-seonyeol/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/Choi-seonyeol/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From /Users/Choi-seonyeol/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/learn/python/learn/datasets/mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input layer\n",
    "X : 28 \\* 28 \\* 1 의  흑백 data <br>\n",
    "Y : 0 ~ 9 사이의 숫자  class <br>\n",
    "keep_prob : drop out 하지 않고, 사용할 node 의 비율"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# input place holders\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "X_img = tf.reshape(X, [-1, 28, 28, 1])   # img 28x28x1 (black/white) -> -1 의 의미는, 알아서 결정하라는 뜻.\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# dropout (keep_prob) rate  0.7~0.5 on training, but should be 1 for testing\n",
    "keep_prob = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv layer 1\n",
    "\n",
    "fillter : [3,3,1,32] -> 3\\*3 짜리 흑백 image 로 각각 한장씩 32개 filter<br>\n",
    "stride : [1,1,1,1] -> 한칸씩 이동<br>\n",
    "padding : \"SAME\" -> 같은 size 가 적용되도록 zero-padding<br>\n",
    "relu : ReLU 적용<br>\n",
    "pool : kernel size : 1장 당 2*2 하나씩, strides : 2*2 로 두칸씩<br>\n",
    "![lec11_26](../../img/lec11_26.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\\nTensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\\nTensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32) !\\n--> 결과 [14,14,32] -> 이것이 두번째 CONV 의 INPUT\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# L1 ImgIn shape=(?, 28, 28, 1)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "#    Conv     -> (?, 28, 28, 32) -> (3*3*1), 32개의 fillter\n",
    "#    Pool     -> (?, 14, 14, 32)\n",
    "L1 = tf.nn.conv2d(X_img, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "# CONV\n",
    "L1 = tf.nn.relu(L1)\n",
    "# ReLU\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1],strides=[1, 2, 2, 1], padding='SAME')\n",
    "# POOL\n",
    "\n",
    "'''\n",
    "Tensor(\"Conv2D:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"Relu:0\", shape=(?, 28, 28, 32), dtype=float32)\n",
    "Tensor(\"MaxPool:0\", shape=(?, 14, 14, 32), dtype=float32) !\n",
    "--> 결과 [14,14,32] -> 이것이 두번째 CONV 의 INPUT\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conv layer 2\n",
    "\n",
    "fillter : [3,3,32,64] -> 3\\*3 짜리 흑백 image 로 각각 한장씩 64개 filter\n",
    "<br>\n",
    "여기서, 앞의 Input 으로부터 depth 가 32이므로, 이를 받는다.\n",
    "<br>\n",
    "stride : [1,1,1,1] -> 한칸씩 이동<br>\n",
    "padding : \"SAME\" -> 같은 size 가 적용되도록 zero-padding<br>\n",
    "relu : ReLU 적용<br>\n",
    "pool : kernel size : 1장 당 2*2 하나씩, strides : 2*2 로 두칸씩<br>\n",
    "![lec11_27](../../img/lec11_27.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\\nTensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\\nTensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\\nTensor(\"Reshape_1:0\",shape = (?,3136),dtype = float32)\\n--> 결과 [1,3136] -> 이것이 FC layer의 INPUT\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "INPUT : Tensor(\"dropout/mul:0\", shape=(?, 14, 14, 32), dtype=float32)\n",
    "\"\"\"\n",
    "# L2 ImgIn shape=(?, 14, 14, 32)\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "#    Conv      ->(?, 14, 14, 64)\n",
    "#    Pool      ->(?, 7, 7, 64)\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "L2 = tf.reshape(L2, [-1,7*7*64])\n",
    "# 우리는 이제, L2를 FC layer의 Input으로 사용할 것인데, reshape을 하기 전까지는 3차원으로 구성되어있다.\n",
    "# 이를 reshape 함수를 써서 1차원의 vector 로 변경해주어  Farward 학습을 진행한다.\n",
    "\n",
    "'''\n",
    "Tensor(\"Conv2D_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"Relu_1:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
    "Tensor(\"MaxPool_1:0\", shape=(?, 7, 7, 64), dtype=float32)\n",
    "Tensor(\"Reshape_1:0\",shape = (?,3136),dtype = float32)\n",
    "--> 결과 [1,3136] -> 이것이 FC layer의 INPUT\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  28\\*28 짜리 이미지가 CONV 두번으로 1*3136 의 vector data 로 변환\n",
    "__이제 이 데이터를 FC layer에 넣어 classification을 진행__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fully Connected(FC, Dense) Layer\n",
    "Input : [7\\*7\\*64] -> [1\\* 3136] 의  vector data<br>\n",
    "Init method : Xavier_initializer<br>\n",
    "Cost : softmax<br>\n",
    "optimizer : Adam\n",
    "\n",
    "![lec11_28](../../img/lec11_28.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "INPUT : Tensor(\"Reshape_1:0\",shape = (?,3136),dtype = float)\n",
    "\"\"\"\n",
    "\n",
    "# Final FC 7x7x64 inputs -> 10outputs\n",
    "W3 = tf.get_variable(\"W3\",shape = [7*7*64,10],initializer = tf.contrib.layers.xavier_initializer_conv2d())\n",
    "# 출력은 10개이기 때문에,shape의 모양에 주의\n",
    "b = tf.Variable(tf.random_normal([10]))\n",
    "hypothesis = tf.matmul(L2, W3) + b\n",
    "\n",
    "# define cost/Loss & optimizer\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = hypothesis, labels = Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning started. It takes sometime.\n",
      "Epoch :  0001 cost =  0.341508756\n",
      "Epoch :  0002 cost =  0.092470534\n",
      "Epoch :  0003 cost =  0.070801435\n",
      "Epoch :  0004 cost =  0.057510390\n",
      "Epoch :  0005 cost =  0.049952429\n",
      "Epoch :  0006 cost =  0.043398253\n",
      "Epoch :  0007 cost =  0.038721363\n",
      "Epoch :  0008 cost =  0.033889739\n",
      "Epoch :  0009 cost =  0.029923751\n",
      "Epoch :  0010 cost =  0.025600706\n",
      "Epoch :  0011 cost =  0.023579466\n",
      "Epoch :  0012 cost =  0.020005190\n",
      "Epoch :  0013 cost =  0.019097268\n",
      "Epoch :  0014 cost =  0.016151725\n",
      "Epoch :  0015 cost =  0.014709784\n",
      "Learning Finished!\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# train my model\n",
    "print(\"Learning started. It takes sometime.\")\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    total_batch = int(mnist.train.num_examples / batch_size)\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        feed_dict = {X: batch_xs, Y: batch_ys}\n",
    "        c, _, = sess.run([cost, optimizer], feed_dict = feed_dict)\n",
    "        avg_cost += c / total_batch\n",
    "    print(\"Epoch : \", \"%04d\" % (epoch + 1), \"cost = \", \"{:.9f}\".format(avg_cost))\n",
    "    \n",
    "print(\"Learning Finished!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test model and check accuracy\n",
    "correct_prediction = tf.equal(tf.argmax(hypothesis, 1),tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Accuracy : \",sess.run(accuracy, feed_dict = {X: mnist.test.images, Y : mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 여기서 더 DEEP  하게 갈 수도 있다.\n",
    "CONV layer(Convolution + Pooling) 3개, FC layer 2개\n",
    "![lec11_29](../../img/lec11_29.png)\n",
    "\n",
    "--> __정확도가 매우 높아진다.__\n",
    "\n",
    "이때, deep 할경우 Drop_out 을 꼭 해줘야 하는 것이 주의.<br>\n",
    "또한, Dropout 시, 마지막 Test때는 dropout 하지 않고(keep_prob : 1) 로 해야하는 것또한 주의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
